{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register a Python Pipeline with PZMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Includes Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jobake\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\jobake\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\jobake\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "C:\\Users\\jobake\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\jobake\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\jobake\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\Users\\jobake\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\jobake\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\jobake\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "C:\\Users\\jobake\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "C:\\Users\\jobake\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n",
      "C:\\Users\\jobake\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n"
     ]
    }
   ],
   "source": [
    "import swat\n",
    "from sasctl import Session\n",
    "import sasctl.pzmm as pzmm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Key Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/\".join(os.getcwd().split(\"\\\\\")[:-1]))\n",
    "from password import wd, hostname, port, username, password, protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(wd+\"Data/\"+\"hmeq.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5960, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "      <th>LOAN</th>\n",
       "      <th>MORTDUE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>REASON</th>\n",
       "      <th>JOB</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>DEROG</th>\n",
       "      <th>DELINQ</th>\n",
       "      <th>CLAGE</th>\n",
       "      <th>NINQ</th>\n",
       "      <th>CLNO</th>\n",
       "      <th>DEBTINC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1100</td>\n",
       "      <td>25860.0</td>\n",
       "      <td>39025.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Other</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.366667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1300</td>\n",
       "      <td>70053.0</td>\n",
       "      <td>68400.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Other</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>121.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>16700.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Other</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.466667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1700</td>\n",
       "      <td>97800.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Office</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BAD  LOAN  MORTDUE     VALUE   REASON     JOB   YOJ  DEROG  DELINQ  \\\n",
       "0    1  1100  25860.0   39025.0  HomeImp   Other  10.5    0.0     0.0   \n",
       "1    1  1300  70053.0   68400.0  HomeImp   Other   7.0    0.0     2.0   \n",
       "2    1  1500  13500.0   16700.0  HomeImp   Other   4.0    0.0     0.0   \n",
       "3    1  1500      NaN       NaN      NaN     NaN   NaN    NaN     NaN   \n",
       "4    0  1700  97800.0  112000.0  HomeImp  Office   3.0    0.0     0.0   \n",
       "\n",
       "        CLAGE  NINQ  CLNO  DEBTINC  \n",
       "0   94.366667   1.0   9.0      NaN  \n",
       "1  121.833333   0.0  14.0      NaN  \n",
       "2  149.466667   1.0  10.0      NaN  \n",
       "3         NaN   NaN   NaN      NaN  \n",
       "4   93.333333   0.0  14.0      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "      <th>LOAN</th>\n",
       "      <th>MORTDUE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>DEROG</th>\n",
       "      <th>DELINQ</th>\n",
       "      <th>CLAGE</th>\n",
       "      <th>NINQ</th>\n",
       "      <th>CLNO</th>\n",
       "      <th>DEBTINC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5960.000000</td>\n",
       "      <td>5960.000000</td>\n",
       "      <td>5442.000000</td>\n",
       "      <td>5848.000000</td>\n",
       "      <td>5445.000000</td>\n",
       "      <td>5252.000000</td>\n",
       "      <td>5380.000000</td>\n",
       "      <td>5652.000000</td>\n",
       "      <td>5450.000000</td>\n",
       "      <td>5738.000000</td>\n",
       "      <td>4693.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.199497</td>\n",
       "      <td>18607.969799</td>\n",
       "      <td>73760.817200</td>\n",
       "      <td>101776.048741</td>\n",
       "      <td>8.922268</td>\n",
       "      <td>0.254570</td>\n",
       "      <td>0.449442</td>\n",
       "      <td>179.766275</td>\n",
       "      <td>1.186055</td>\n",
       "      <td>21.296096</td>\n",
       "      <td>33.779915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.399656</td>\n",
       "      <td>11207.480417</td>\n",
       "      <td>44457.609458</td>\n",
       "      <td>57385.775334</td>\n",
       "      <td>7.573982</td>\n",
       "      <td>0.846047</td>\n",
       "      <td>1.127266</td>\n",
       "      <td>85.810092</td>\n",
       "      <td>1.728675</td>\n",
       "      <td>10.138933</td>\n",
       "      <td>8.601746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>2063.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.524499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11100.000000</td>\n",
       "      <td>46276.000000</td>\n",
       "      <td>66075.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>115.116702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>29.140031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16300.000000</td>\n",
       "      <td>65019.000000</td>\n",
       "      <td>89235.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>173.466667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>34.818262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>23300.000000</td>\n",
       "      <td>91488.000000</td>\n",
       "      <td>119824.250000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>231.562278</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>39.003141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>89900.000000</td>\n",
       "      <td>399550.000000</td>\n",
       "      <td>855909.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1168.233561</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>203.312149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               BAD          LOAN        MORTDUE          VALUE          YOJ  \\\n",
       "count  5960.000000   5960.000000    5442.000000    5848.000000  5445.000000   \n",
       "mean      0.199497  18607.969799   73760.817200  101776.048741     8.922268   \n",
       "std       0.399656  11207.480417   44457.609458   57385.775334     7.573982   \n",
       "min       0.000000   1100.000000    2063.000000    8000.000000     0.000000   \n",
       "25%       0.000000  11100.000000   46276.000000   66075.500000     3.000000   \n",
       "50%       0.000000  16300.000000   65019.000000   89235.500000     7.000000   \n",
       "75%       0.000000  23300.000000   91488.000000  119824.250000    13.000000   \n",
       "max       1.000000  89900.000000  399550.000000  855909.000000    41.000000   \n",
       "\n",
       "             DEROG       DELINQ        CLAGE         NINQ         CLNO  \\\n",
       "count  5252.000000  5380.000000  5652.000000  5450.000000  5738.000000   \n",
       "mean      0.254570     0.449442   179.766275     1.186055    21.296096   \n",
       "std       0.846047     1.127266    85.810092     1.728675    10.138933   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000   115.116702     0.000000    15.000000   \n",
       "50%       0.000000     0.000000   173.466667     1.000000    20.000000   \n",
       "75%       0.000000     0.000000   231.562278     2.000000    26.000000   \n",
       "max      10.000000    15.000000  1168.233561    17.000000    71.000000   \n",
       "\n",
       "           DEBTINC  \n",
       "count  4693.000000  \n",
       "mean     33.779915  \n",
       "std       8.601746  \n",
       "min       0.524499  \n",
       "25%      29.140031  \n",
       "50%      34.818262  \n",
       "75%      39.003141  \n",
       "max     203.312149  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4771\n",
       "1    1189\n",
       "Name: BAD, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"BAD\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other      2388\n",
       "ProfExe    1276\n",
       "Office      948\n",
       "Mgr         767\n",
       "Self        193\n",
       "Sales       109\n",
       "Name: JOB, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"JOB\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebtCon    3928\n",
       "HomeImp    1780\n",
       "Name: REASON, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"REASON\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BAD           0\n",
       "LOAN          0\n",
       "MORTDUE     518\n",
       "VALUE       112\n",
       "REASON      252\n",
       "JOB         279\n",
       "YOJ         515\n",
       "DEROG       708\n",
       "DELINQ      580\n",
       "CLAGE       308\n",
       "NINQ        510\n",
       "CLNO        222\n",
       "DEBTINC    1267\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"LOAN\",\"MORTDUE\",\"VALUE\",\"YOJ\",\"DEROG\",\"DELINQ\",\"CLAGE\",\"NINQ\",\"CLNO\",\"DEBTINC\"]\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"JOB\",\"REASON\"]\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols),\n",
    "        ('cat', cat_transformer, cat_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"BAD\"\n",
    "inputs = num_cols + cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape = (4172, 13)\n",
      "Valid Data Shape     = (1192, 13)\n",
      "Test Data Shape     = (596, 13)\n"
     ]
    }
   ],
   "source": [
    "train_pct = 0.70\n",
    "valid_pct = 0.20\n",
    "test_pct = 0.10\n",
    "nrows = len(df)\n",
    "myseq = list(range(nrows))\n",
    "\n",
    "random.seed(802)\n",
    "train_index = random.sample(myseq,round(nrows*train_pct))\n",
    "valid_test_index = list(set(myseq) - set(train_index))\n",
    "\n",
    "valid_index = random.sample(valid_test_index,round(nrows*valid_pct))\n",
    "test_index = list(set(valid_test_index) - set(valid_index))\n",
    "\n",
    "df_train = df.iloc[train_index]\n",
    "print(\"Training Data Shape =\",df_train.shape)\n",
    "df_valid = df.iloc[valid_index]\n",
    "print(\"Valid Data Shape     =\",df_valid.shape)\n",
    "df_test = df.iloc[test_index]\n",
    "print(\"Test Data Shape     =\",df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='median',\n",
       "                                                                                 verbose=0))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['LOAN', 'MORTDUE', 'VALUE',\n",
       "                                                   'Y...\n",
       "                                                                                 handle_unknown='ignore',\n",
       "                                                                                 n_values=None,\n",
       "                                                                                 sparse=False))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['JOB', 'REASON'])],\n",
       "                                   verbose=False)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=802,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=802)\n",
    "pipeline_lr = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', lr)])\n",
    "\n",
    "pipeline_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jobake\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='median',\n",
       "                                                                                 verbose=0))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['LOAN', 'MORTDUE', 'VALUE',\n",
       "                                                   'Y...\n",
       "                                                                                 handle_unknown='ignore',\n",
       "                                                                                 n_values=None,\n",
       "                                                                                 sparse=False))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['JOB', 'REASON'])],\n",
       "                                   verbose=False)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=802,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_lr.fit(df_train[num_cols+cat_cols],df_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DEBTINC</td>\n",
       "      <td>0.014405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CLAGE</td>\n",
       "      <td>-0.008076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DELINQ</td>\n",
       "      <td>0.005688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CLNO</td>\n",
       "      <td>0.005547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NINQ</td>\n",
       "      <td>0.003814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEROG</td>\n",
       "      <td>0.003271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YOJ</td>\n",
       "      <td>-0.002838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>REASON</td>\n",
       "      <td>-0.000519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JOB</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOAN</td>\n",
       "      <td>-0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MORTDUE</td>\n",
       "      <td>-0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VALUE</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature      coef\n",
       "9   DEBTINC  0.014405\n",
       "6     CLAGE -0.008076\n",
       "5    DELINQ  0.005688\n",
       "8      CLNO  0.005547\n",
       "7      NINQ  0.003814\n",
       "4     DEROG  0.003271\n",
       "3       YOJ -0.002838\n",
       "11   REASON -0.000519\n",
       "10      JOB  0.000206\n",
       "0      LOAN -0.000027\n",
       "1   MORTDUE -0.000007\n",
       "2     VALUE  0.000003"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = pipeline_lr[\"classifier\"].coef_.flatten()\n",
    "coef = pd.DataFrame(zip(num_cols+cat_cols, coefs), columns=[\"feature\", \"coef\"])\n",
    "coef[\"abs_coef\"] = coef[\"coef\"].apply(lambda x: abs(x))\n",
    "coef = coef.sort_values(\"abs_coef\", ascending=False)\n",
    "coef = coef.drop(columns='abs_coef')\n",
    "coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train Accuracy = 0.8058\n",
      "Logistic Regression Valid Accuracy = 0.7752\n",
      "Logistic Regression Test Accuracy = 0.8188\n"
     ]
    }
   ],
   "source": [
    "lr_score_train = pipeline_lr.score(X=df_train[inputs], y=df_train[target])\n",
    "print(\"Logistic Regression Train Accuracy =\", round(lr_score_train,4))\n",
    "\n",
    "lr_score_valid = pipeline_lr.score(X=df_valid[inputs], y=df_valid[target])\n",
    "print(\"Logistic Regression Valid Accuracy =\", round(lr_score_valid,4))\n",
    "\n",
    "lr_score_test = pipeline_lr.score(X=df_test[inputs], y=df_test[target])\n",
    "print(\"Logistic Regression Test Accuracy =\", round(lr_score_test,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train ROC = 0.6734\n",
      "Logistic Regression Valid ROC = 0.6342\n",
      "Logistic Regression test ROC = 0.6739\n"
     ]
    }
   ],
   "source": [
    "lr_auc_train = roc_auc_score(y_true=df_train[target], y_score=pipeline_lr.predict_proba(df_train[inputs])[:, 1])\n",
    "print(\"Logistic Regression Train ROC =\", round(lr_auc_train,4))\n",
    "\n",
    "lr_auc_valid = roc_auc_score(y_true=df_valid[target], y_score=pipeline_lr.predict_proba(df_valid[inputs])[:, 1])\n",
    "print(\"Logistic Regression Valid ROC =\", round(lr_auc_valid,4))\n",
    "\n",
    "lr_auc_test = roc_auc_score(y_true=df_test[target], y_score=pipeline_lr.predict_proba(df_test[inputs])[:, 1])\n",
    "print(\"Logistic Regression test ROC =\", round(lr_auc_test,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = Session(hostname, username, password)\n",
    "# conn = sess.as_swat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Metadata Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.getcwd()+\"\\\\Model_Manager\\\\Metadata\"\n",
    "model_name = \"Python_Sklearn_LR_Pipeline\"\n",
    "data_name = \"HMEQ\"\n",
    "zip_folder = output_dir +\"\\\\\"+ data_name +\"_\"+ model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(zip_folder):\n",
    "    shutil.rmtree(zip_folder)\n",
    "\n",
    "os.makedirs(zip_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"HMEQ_Pipeline\"\n",
    "project_name = \"MM_OS_Test\"\n",
    "metric_labels = ['EM_EVENTPROBABILITY', 'EM_CLASSIFICATION']\n",
    "output_data = pd.DataFrame(columns=metric_labels, data=[[0.5, 'A']])\n",
    "model_type = \"Gradient Boosting\"\n",
    "target_event_level = 1\n",
    "target_levels = 2\n",
    "predict_syntax = \"predict_proba\"\n",
    "predict_method = str('{}.')+str(predict_syntax)+str('({})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Python_Sklearn_LR_Pipeline was successfully pickled and saved to C:\\Users\\jobake\\FSBU\\Model_Manager\\Metadata\\HMEQ_Python_Sklearn_LR_Pipeline\\Python_Sklearn_LR_Pipeline.pickle.\n",
      "inputVar.json was successfully written and saved to C:\\Users\\jobake\\FSBU\\Model_Manager\\Metadata\\HMEQ_Python_Sklearn_LR_Pipeline\\inputVar.json\n",
      "outputVar.json was successfully written and saved to C:\\Users\\jobake\\FSBU\\Model_Manager\\Metadata\\HMEQ_Python_Sklearn_LR_Pipeline\\outputVar.json\n"
     ]
    }
   ],
   "source": [
    "pzmm.PickleModel.pickleTrainedModel(_, \n",
    "                                    trainedModel = pipeline_lr, \n",
    "                                    modelPrefix = model_name, \n",
    "                                    pPath = zip_folder)\n",
    "\n",
    "pzmm.JSONFiles().writeVarJSON(inputData = df_train[inputs], \n",
    "                              isInput = True, \n",
    "                              jPath = zip_folder)\n",
    "\n",
    "pzmm.JSONFiles().writeVarJSON(inputData = output_data, \n",
    "                              isInput = False, \n",
    "                              jPath = zip_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proba = pipeline_lr.predict_proba(df_train[inputs])\n",
    "df_train_obs_preds = pd.concat([df_train[target].reset_index(drop=True), pd.Series(data=train_proba[:,1])], axis=1)\n",
    "df_train_obs_preds.columns = [target, \"P_\"+target+str(1)]\n",
    "\n",
    "valid_proba = pipeline_lr.predict_proba(df_valid[inputs])\n",
    "df_valid_obs_preds = pd.concat([df_valid[target].reset_index(drop=True), pd.Series(data=valid_proba[:,1])], axis=1)\n",
    "df_valid_obs_preds.columns = [target, \"P_\"+target+str(1)]\n",
    "\n",
    "test_proba = pipeline_lr.predict_proba(df_test[inputs])\n",
    "df_test_obs_preds = pd.concat([df_test[target].reset_index(drop=True), pd.Series(data=test_proba[:,1])], axis=1)\n",
    "df_test_obs_preds.columns = [target, \"P_\"+target+str(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dmcas_fitstat.json was successfully written and saved to C:\\Users\\jobake\\FSBU\\Model_Manager\\Metadata\\HMEQ_Python_Sklearn_LR_Pipeline\\dmcas_fitstat.json\n",
      "NOTE: Added action set 'percentile'.\n",
      "NOTE: Cloud Analytic Services made the uploaded file available as table SCOREDVALUES in caslib CASUSER(jobake).\n",
      "NOTE: The table SCOREDVALUES has been created in caslib CASUSER(jobake) from binary data uploaded to Cloud Analytic Services.\n",
      "NOTE: Cloud Analytic Services made the uploaded file available as table SCOREDVALUES in caslib CASUSER(jobake).\n",
      "NOTE: The table SCOREDVALUES has been created in caslib CASUSER(jobake) from binary data uploaded to Cloud Analytic Services.\n",
      "NOTE: Cloud Analytic Services made the uploaded file available as table SCOREDVALUES in caslib CASUSER(jobake).\n",
      "NOTE: The table SCOREDVALUES has been created in caslib CASUSER(jobake) from binary data uploaded to Cloud Analytic Services.\n",
      "dmcas_roc.json was successfully written and saved to C:\\Users\\jobake\\FSBU\\Model_Manager\\Metadata\\HMEQ_Python_Sklearn_LR_Pipeline\\dmcas_roc.json\n",
      "dmcas_lift.json was successfully written and saved to C:\\Users\\jobake\\FSBU\\Model_Manager\\Metadata\\HMEQ_Python_Sklearn_LR_Pipeline\\dmcas_lift.json\n"
     ]
    }
   ],
   "source": [
    "pzmm.JSONFiles().calculateFitStat(trainData = df_train_obs_preds, \n",
    "                                  validateData = df_valid_obs_preds, \n",
    "                                  testData = df_test_obs_preds, \n",
    "                                  jPath = zip_folder)\n",
    "\n",
    "pzmm.JSONFiles().generateROCLiftStat(targetName = target, \n",
    "                                     targetValue = target_event_level, \n",
    "                                     swatConn = conn, \n",
    "                                     trainData = df_train_obs_preds, \n",
    "                                     validateData = df_valid_obs_preds, \n",
    "                                     testData = df_test_obs_preds, \n",
    "                                     jPath = zip_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileMetaData.json was successfully written and saved to C:\\Users\\jobake\\FSBU\\Model_Manager\\Metadata\\HMEQ_Python_Sklearn_LR_Pipeline\\fileMetaData.json\n",
      "ModelProperties.json was successfully written and saved to C:\\Users\\jobake\\FSBU\\Model_Manager\\Metadata\\HMEQ_Python_Sklearn_LR_Pipeline\\ModelProperties.json\n"
     ]
    }
   ],
   "source": [
    "pzmm.JSONFiles().writeFileMetadataJSON(modelPrefix = model_name, \n",
    "                                       jPath = zip_folder)\n",
    "\n",
    "pzmm.JSONFiles().writeModelPropertiesJSON(modelName = model_name, \n",
    "                                          modelDesc = model_name,\n",
    "                                          targetVariable = target,\n",
    "                                          modelType = model_type,\n",
    "                                          modelPredictors = inputs,\n",
    "                                          targetEvent = target_event_level,\n",
    "                                          numTargetCategories = target_levels,\n",
    "                                          eventProbVar = metric_labels[0],\n",
    "                                          jPath = zip_folder,\n",
    "                                          modeler = username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pzmm.ImportModel().pzmmImportModel(zPath = zip_folder, \n",
    "#                                    modelPrefix = model_name, \n",
    "#                                    project = project_name, \n",
    "#                                    inputDF = df_train[inputs], \n",
    "#                                    targetDF = df_train[target], \n",
    "#                                    predictmethod = predict_method, \n",
    "#                                    metrics = metric_labels, \n",
    "#                                    force = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.00407s</span> &#183; <span class=\"cas-user\">user 0.00161s</span> &#183; <span class=\"cas-sys\">sys 0.00512s</span> &#183; <span class=\"cas-memory\">mem 0.839MB</span></small></p>"
      ],
      "text/plain": [
       "+ Elapsed: 0.00407s, user: 0.00161s, sys: 0.00512s, mem: 0.839mb"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.session.endSession()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
